{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Project Part-1\n",
        "## Colab Notebook For CNN\n",
        "**Connect Four**\n",
        "\n",
        "Author: Pranath Reddy Kumbam\n",
        "\n",
        "UFID: 8512-0977\n",
        "\n",
        "- Notebook for training a simple CNN model on Balanced Connect Four Dataset"
      ],
      "metadata": {
        "id": "xtUTBDgOuOyl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uV8Lch-wnW32"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fltk46feoNyW"
      },
      "outputs": [],
      "source": [
        "cd drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22rFozDqoQxm"
      },
      "outputs": [],
      "source": [
        "cd My \\Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DuSmOjVKoU-S"
      },
      "outputs": [],
      "source": [
        "cd DLCG/Project1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU Info\n",
        "!nvidia-smi "
      ],
      "metadata": {
        "id": "oMHFR_8gaxKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get CUDA Info\n",
        "!nvcc --version"
      ],
      "metadata": {
        "id": "yDNrNHcrj0A2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "agXdpFwPPiHw"
      },
      "outputs": [],
      "source": [
        "# Import libraries \n",
        "from sklearn.utils import shuffle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pickle\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Define CNN Model\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Conv2d(1, 6, 3),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(6, 12, 3),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(72, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 3)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# Push the model to device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CNN().to(device)\n",
        "\n",
        "# Load Data\n",
        "data = pd.read_csv('./Data/connectfour.data', sep= ',', header = None)\n",
        "encoding = {\"x\":2, \"o\":1, \"b\":0, \"win\":0, \"loss\":1, \"draw\":2}\n",
        "data = data.replace(encoding).to_numpy()\n",
        "\n",
        "# Balance the Data based on Class with lowest No Of samples\n",
        "data_win = np.asarray([sample for sample in data if sample[-1] == 1])\n",
        "data_loss = np.asarray([sample for sample in data if sample[-1] == 0])\n",
        "data_draw = np.asarray([sample for sample in data if sample[-1] == 2])\n",
        "data = (np.concatenate((data_win[:data_draw.shape[0]], data_loss[:data_draw.shape[0]], data_draw)))\n",
        "np.random.shuffle(data)\n",
        "\n",
        "# Split the data into validation set\n",
        "x, x_val, y, y_val = train_test_split(data[:,:-1], data[:,-1].reshape(-1), test_size=0.05)\n",
        "\n",
        "# Reshape samples into 2D\n",
        "x = x.reshape(x.shape[0], 1, 6, 7)\n",
        "x_val = x_val.reshape(x_val.shape[0], 1, 6, 7)\n",
        "print(x.shape)\n",
        "print(x_val.shape)\n",
        "\n",
        "# Shuffle\n",
        "x, y = shuffle(x, y, random_state=0)\n",
        "x_val, y_val = shuffle(x_val, y_val, random_state=0)\n",
        "\n",
        "# MLP Optimizer \n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=2e-3, weight_decay=1e-5)\n",
        "criteria = nn.CrossEntropyLoss() # Loss Function\n",
        "n_epochs = 200 # Training Epochs\n",
        "\n",
        "# Multi-Class Classification\n",
        "# Use K-Fold Cross Validation\n",
        "print(\"Multi-Class Classification\\n\")\n",
        "MLP_Scores = []\n",
        "fold_index = 1\n",
        "for train_index, test_index in KFold(n_splits=10).split(x):\n",
        "    print('Fold: ' + str(fold_index) + '\\n')\n",
        "    x_tr, x_ts = x[train_index], x[test_index]\n",
        "    y_tr, y_ts = y[train_index], y[test_index]\n",
        "\n",
        "    model.train()\n",
        "    for epoch in tqdm(range(1, n_epochs+1)):\n",
        "      for i in range(int(x_tr.shape[0]/100)):\n",
        "\n",
        "        data = torch.from_numpy(x_tr[(100*i): (100*i)+100].astype(np.float32))\n",
        "        if torch.cuda.is_available():\n",
        "          data = data.cuda()\n",
        "        labels = torch.tensor(y_tr[(100*i): (100*i)+100], dtype=torch.long, device=device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(data)\n",
        "        _, preds = torch.max(model(data).data, 1)\n",
        "        correct = (preds == labels).float().sum()\n",
        "        loss = criteria(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    x_ts_torch = torch.from_numpy(x_ts.astype(np.float32)).cuda()\n",
        "    _, yp_CNN = torch.max(model(x_ts_torch).data, 1)\n",
        "    yp_CNN = yp_CNN.cpu().detach().numpy()\n",
        "\n",
        "    acc_CNN = accuracy_score(y_ts, yp_CNN)\n",
        "    print(\"CNN Accuracy: \" + str(acc_CNN) + '\\n')\n",
        "    MLP_Scores.append(acc_CNN)\n",
        "    print(\"CNN Confusion Matrix: \" + '\\n')\n",
        "    confmat = confusion_matrix(y_ts, yp_CNN, normalize='true')\n",
        "    for row in confmat:\n",
        "        print(*row, sep=\"\\t\")\n",
        "    print(\"\")\n",
        "    print(\"________________________________________________________  \\n\")\n",
        "\n",
        "    # Reset Model and optimizer\n",
        "    for layer in model.children():\n",
        "      if hasattr(layer, 'reset_parameters'):\n",
        "        layer.reset_parameters()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=2e-3, weight_decay=1e-5)\n",
        "\n",
        "    fold_index += 1\n",
        "\n",
        "print(\"Results: \")\n",
        "print(\"CNN Accuracy: \" + str(np.mean(MLP_Scores)) + \" +/- \" + str(np.std(MLP_Scores)))\n",
        "\n",
        "# Train to deploy model\n",
        "model.train()\n",
        "for epoch in tqdm(range(1, n_epochs+1)):\n",
        "    for i in range(int(x.shape[0]/100)):\n",
        "\n",
        "        data = torch.from_numpy(x[(100*i): (100*i)+100].astype(np.float32))\n",
        "        if torch.cuda.is_available():\n",
        "          data = data.cuda()\n",
        "        labels = torch.tensor(y[(100*i): (100*i)+100], dtype=torch.long, device=device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(data)\n",
        "        _, preds = torch.max(model(data).data, 1)\n",
        "        correct = (preds == labels).float().sum()\n",
        "        loss = criteria(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Export trained model\n",
        "torch.save(model, './CNN_Connect4_Balanced.pth')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}